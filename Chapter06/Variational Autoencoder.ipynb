{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torch import optim\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import save_image\n",
    "import torch.nn.functional as F\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./mlp_img'):\n",
    "    os.mkdir('./mlp_img')\n",
    "\n",
    "number_epochs = 10\n",
    "batch_size = 128\n",
    "learning_rate = 1e-4\n",
    "\n",
    "transform_image = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "dataset = MNIST('./data', transform=transform_image)\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "def to_image(x):\n",
    "    x = 0.5 * (x + 1)\n",
    "    x = x.clamp(0, 1)\n",
    "    x = x.view(x.size(0), 1, 28, 28)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 1507.728882\n",
      "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 832.425720\n",
      "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 777.984314\n",
      "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 761.669189\n",
      "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 747.355591\n",
      "Epoch: 0 Average loss: 831.2576\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 747.032776\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 740.493469\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 739.800781\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 738.366272\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 735.688477\n",
      "Epoch: 1 Average loss: 739.2957\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 735.274780\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 735.723389\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 733.795105\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 730.536743\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 732.716736\n",
      "Epoch: 2 Average loss: 733.2621\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 730.552795\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 731.892944\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 731.057800\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 729.299561\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 729.192627\n",
      "Epoch: 3 Average loss: 730.7840\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 730.493774\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 728.583801\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 729.074890\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 728.214355\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 729.022034\n",
      "Epoch: 4 Average loss: 728.8413\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 732.420532\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 725.454712\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 725.733887\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 728.440369\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 726.494446\n",
      "Epoch: 5 Average loss: 727.0280\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 726.308716\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 726.226624\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 726.271729\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 725.267273\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 726.751343\n",
      "Epoch: 6 Average loss: 725.6692\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 723.961670\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 726.573364\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 723.579346\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 724.690979\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 726.122742\n",
      "Epoch: 7 Average loss: 724.0818\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 725.173340\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 725.153870\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 720.867371\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 720.868225\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 718.580566\n",
      "Epoch: 8 Average loss: 722.1473\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 723.599426\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 718.821655\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 718.787598\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 719.600281\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 721.149353\n",
      "Epoch: 9 Average loss: 720.5181\n"
     ]
    }
   ],
   "source": [
    "class VariationalAutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VariationalAutoEncoder, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(784, 400)\n",
    "        self.fc21 = nn.Linear(400, 20)\n",
    "        self.fc22 = nn.Linear(400, 20)\n",
    "        self.fc3 = nn.Linear(20, 400)\n",
    "        self.fc4 = nn.Linear(400, 784)\n",
    "\n",
    "    def encode_function(self, x):\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "\n",
    "    def reparametrize(self, mu, logvar):\n",
    "        std = logvar.mul(0.5).exp_()\n",
    "        if torch.cuda.is_available():\n",
    "            eps = torch.cuda.FloatTensor(std.size()).normal_()\n",
    "        else:\n",
    "            eps = torch.FloatTensor(std.size()).normal_()\n",
    "        eps = Variable(eps)\n",
    "        return eps.mul(std).add_(mu)\n",
    "\n",
    "    def decode_function(self, z):\n",
    "        h3 = F.relu(self.fc3(z))\n",
    "        return F.sigmoid(self.fc4(h3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode_function(x)\n",
    "        z = self.reparametrize(mu, logvar)\n",
    "        return self.decode_function(z), mu, logvar\n",
    "\n",
    "\n",
    "model = VariationalAutoEncoder()\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "\n",
    "reconstruction_function = nn.MSELoss(size_average=False)\n",
    "\n",
    "\n",
    "def loss_function(reconstruction_x, x, mu, latent_log_variance):\n",
    "    \"\"\"\n",
    "    reconstruction_x: generating images\n",
    "    x: original images\n",
    "    mu: latent mean\n",
    "    \"\"\"\n",
    "    BCE = reconstruction_function(reconstruction_x, x)  \n",
    "    # KL loss = 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD_aspect = mu.pow(2).add_(latent_log_variance.exp()).mul_(-1).add_(1).add_(logvar)\n",
    "    KLD = torch.sum(KLD_aspect).mul_(-0.5)\n",
    "    # KL divergence\n",
    "    return BCE + KLD\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "for epoch in range(number_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, data in enumerate(data_loader):\n",
    "        img, _ = data\n",
    "        img = img.view(img.size(0), -1)\n",
    "        img = Variable(img)\n",
    "        if torch.cuda.is_available():\n",
    "            img = img.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(img)\n",
    "        loss = loss_function(recon_batch, img, mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.data[0]\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch,\n",
    "                batch_idx * len(img),\n",
    "                len(data_loader.dataset), 100. * batch_idx / len(data_loader),\n",
    "                loss.data[0] / len(img)))\n",
    "\n",
    "    print('Epoch: {} Average loss: {:.4f}'.format(epoch, train_loss / len(data_loader.dataset)))\n",
    "    if epoch % 10 == 0:\n",
    "        save = to_image(recon_batch.cpu().data)\n",
    "        save_image(save, './vae_img/image_{}.png'.format(epoch))\n",
    "\n",
    "torch.save(model.state_dict(), './vae.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
