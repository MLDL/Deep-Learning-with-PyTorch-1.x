{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic ResNet block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self,in_channels,output_channels,stride):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.convolutional_1 = nn.Conv2d(input_channels,output_channels,kernel_size=3,stride=stride,padding=1,bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(output_channels)\n",
    "        self.convolutional_2 = nn.Conv2d(output_channels,output_channels,kernel_size=3,stride=stride,padding=1,bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(output_channels)\n",
    "        self.stride = stride\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        residual = x\n",
    "        out = self.convolutional_1(x)\n",
    "        out = F.relu(self.bn1(out),inplace=True)\n",
    "        out = self.convolutional_2(out)\n",
    "        out = self.bn2(out)\n",
    "        out += residual\n",
    "        return F.relu(out)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inception block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicConvolutional2d(nn.Module):\n",
    "\n",
    "    def __init__(self, input_channels, output_channels, **kwargs):\n",
    "        super(BasicConv2d, self).__init__()\n",
    "        self.conv = nn.Conv2d(input_channels, output_channels, bias=False, **kwargs)\n",
    "        self.bn = nn.BatchNorm2d(output_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        return F.relu(x, inplace=True)\n",
    "\n",
    "\n",
    "class InceptionBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, input_channels, pool_features):\n",
    "        super().__init__()\n",
    "        self.inception_branch_1x1 = BasicConv2d(input_channels, 64, kernel_size=1)\n",
    "\n",
    "        self.inception_branch_5x5_1 = BasicConv2d(input_channels, 48, kernel_size=1)\n",
    "        self.inception_branch_5x5_2 = BasicConv2d(48, 64, kernel_size=5, padding=2)\n",
    "\n",
    "        self.inception_branch_3x3dbl_1 = BasicConv2d(input_channels, 64, kernel_size=1)\n",
    "        self.inception_branch_3x3dbl_2 = BasicConv2d(64, 96, kernel_size=3, padding=1)\n",
    "\n",
    "        self.inception_branch_pool = BasicConv2d(input_channels, pool_features, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        inception_branch_1x1 = self.inception_branch1x1(x)\n",
    "\n",
    "        inception_branch_5x5 = self.inception_branch_5x5_1(x)\n",
    "        inception_branch_5x5 = self.inception_branch_5x5_2(branch5x5)\n",
    "\n",
    "        inception_branch_3x3dbl = self.inception_branch_3x3dbl_1(x)\n",
    "        inception_branch_3x3dbl = self.inception_branch_3x3dbl_2(inception_branch3x3dbl)\n",
    "\n",
    "        branch_pool = F.avg_pool2d(x, kernel_size=3, stride=1, padding=1)\n",
    "        branch_pool = self.branch_pool(branch_pool)\n",
    "\n",
    "        outputs = [inception_branch_1x1, inception_branch_5x5, inception_branch_3x3dbl, inception_branch_pool]\n",
    "        return torch.cat(outputs, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DenseNet Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _DenseBlock(nn.Sequential):\n",
    "    def __init__(self, number_layers, number_input_features, bn_size, growth_rate, drop_rate):\n",
    "        super(_DenseBlock, self).__init__()\n",
    "        for i in range(number_layers):\n",
    "            layer = _DenseLayer(number_input_features + i * growth_rate, growth_rate, bn_size, drop_rate)\n",
    "            self.add_module('denselayer%d' % (i + 1), layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _DenseLayer(nn.Sequential):\n",
    "    def __init__(self, number_input_features, growth_rate, bn_size, drop_rate):\n",
    "        super(_DenseLayer, self).__init__()\n",
    "        self.add_module('norm.1', nn.BatchNorm2d(number_input_features)),\n",
    "        self.add_module('relu.1', nn.ReLU(inplace=True)),\n",
    "        self.add_module('conv.1', nn.Conv2d(number_input_features, bn_size *\n",
    "                       growth_rate, kernel_size=1, stride=1, bias=False)),\n",
    "        self.add_module('norm.2', nn.BatchNorm2d(bn_size * growth_rate)),\n",
    "        self.add_module('relu.2', nn.ReLU(inplace=True)),\n",
    "        self.add_module('conv.2', nn.Conv2d(bn_size * growth_rate, growth_rate,\n",
    "                       kernel_size=3, stride=1, padding=1, bias=False)),\n",
    "        self.drop_rate = drop_rate\n",
    "\n",
    "    def forward(self, x):\n",
    "        new_features = super(_DenseLayer, self).forward(x)\n",
    "        if self.drop_rate > 0:\n",
    "            new_features = F.dropout(new_features, p=self.drop_rate, training=self.training)\n",
    "        return torch.cat([x, new_features], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
